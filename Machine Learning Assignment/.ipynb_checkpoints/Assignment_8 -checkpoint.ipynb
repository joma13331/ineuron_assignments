{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294ac3a2",
   "metadata": {},
   "source": [
    "**Q1. What exactly is a feature? Give an example to illustrate your point.**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346c098",
   "metadata": {},
   "source": [
    "Features are the basic building blocks of datasets. The quality of the features in your dataset has a major impact on the quality of the insights you will gain when you use that dataset for machine learning.\n",
    "\n",
    "Additionally, different business problems within the same industry do not necessarily require the same features, which is why it is important to have a strong understanding of the business goals of your data science project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62723e26",
   "metadata": {},
   "source": [
    "**Q2. What are the various circumstances in which feature construction is required?**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29167080",
   "metadata": {},
   "source": [
    "The features in your data will directly influence the predictive models you use and the results you can achieve. Your results are dependent on many inter-dependent properties. You need great features that describe the structures inherent in your data. Better features means flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4de3dd",
   "metadata": {},
   "source": [
    "**Q3. Describe how nominal variables are encoded.**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00844faa",
   "metadata": {},
   "source": [
    "1. Using One Hot Encoding\n",
    "2. Count Encodeong\n",
    "3. Pandas get_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71688dad",
   "metadata": {},
   "source": [
    "**Q4. Describe how numeric features are converted to categorical features.**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd51164",
   "metadata": {},
   "source": [
    " Converting categorical features into numeric features using domain knowledge. For example, we are given a list of countries and say we know the distance to these countries from India then we can replace it with distance from India. So, every country can be represented as its distance from India.\n",
    " \n",
    " * Using np.where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96633849",
   "metadata": {},
   "source": [
    "**Q5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?*\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22de1d",
   "metadata": {},
   "source": [
    "Wrapper methods measure the “usefulness” of features based on the classifier performance. In contrast, the filter methods pick up the intrinsic properties of the features (i.e., the “relevance” of the features) measured via univariate statistics instead of cross-validation performance.\n",
    "\n",
    "The wrapper classification algorithms with joint dimensionality reduction and classification can also be used but these methods have high computation cost, lower discriminative power. Moreover, these methods depend on the efficient selection of classifiers for obtaining high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0d6bb",
   "metadata": {},
   "source": [
    "**Q6. When is a feature considered irrelevant? What can be said to quantify it?**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5847c",
   "metadata": {},
   "source": [
    "Features are considered relevant if they are either strongly or weakly relevant, and are considered irrelevant otherwise.\n",
    "\n",
    "Irrelevant features can never contribute to prediction accuracy, by definition. Also to quantify it we need to first check the list of features, There are three types of feature selection:\n",
    "\n",
    "    Wrapper methods (forward, backward, and stepwise selection)\n",
    "    Filter methods (ANOVA, Pearson correlation, variance thresholding)\n",
    "    Embedded methods (Lasso, Ridge, Decision Tree).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a99205",
   "metadata": {},
   "source": [
    "**Q7. When is a function considered redundant? What criteria are used to identify features that could be redundant?**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe72388",
   "metadata": {},
   "source": [
    "If two features {X1, X2} are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure. In other words, the correlation measure provides statistical association between any given a pair of features.\n",
    "\n",
    "Minimum redundancy feature selection is an algorithm frequently used in a method to accurately identify characteristics of genes and phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f99b74",
   "metadata": {},
   "source": [
    "**Q8. What are the various distance measurements used to determine feature similarity?**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f99ff0",
   "metadata": {},
   "source": [
    "\n",
    "    Hamming Distance.\n",
    "    Euclidean Distance\n",
    "    Manhattan Distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca6293",
   "metadata": {},
   "source": [
    "**Q9. State difference between Euclidean and Manhattan distances?**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98c609e0",
   "metadata": {},
   "source": [
    "1. Euclidean distance is one of the most used distance metrics. It is calculated using Minkowski Distance formula by setting p’s value to 2.\n",
    "    ![Euclidean Distance](https://d1zx6djv3kb1v7.cloudfront.net/wp-content/media/2019/11/Euclidean-Distance-i2tutorials.png)\n",
    "    \n",
    "2. Manhattan distance is a distance metric between two points in a N dimensional vector space. It is the sum of the lengths of the projections of the line segment between the points onto the coordinate axes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346425f",
   "metadata": {},
   "source": [
    "**Q10. Distinguish between feature transformation and feature selection.**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ba164",
   "metadata": {},
   "source": [
    "Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d28fbd",
   "metadata": {},
   "source": [
    "**Q11. Make brief notes on any two of the following:**\n",
    "\n",
    "1. **SVD (Standard Variable Diameter Diameter)**\n",
    "\n",
    "2. **Collection of features using a hybrid approach**\n",
    "\n",
    "3. **The width of the silhouette**\n",
    "\n",
    "4. **Receiver operating characteristic curve**\n",
    "\n",
    "SOLUTION IN NEXT CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38581861",
   "metadata": {},
   "source": [
    "3. The width of the silhouette\n",
    "    * Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified\n",
    "    * The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters. \n",
    "4. Receiver operating characteristic curve:\n",
    "    * characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "    * The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
